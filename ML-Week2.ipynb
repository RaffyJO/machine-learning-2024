{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLxwlcG4/hu0cc3eb6vN2J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaffyJO/machine-learning-2024/blob/main/ML-Week2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nama: Raffy Jamil Octavialdy\n",
        "<br>\n",
        "Kelas: TI - 3D\n",
        "<br>\n",
        "NIM: 2241720082**"
      ],
      "metadata": {
        "id": "CR8bEE0k40R8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kode 1-1 merupakan implementasi normalisasi berdasarkan Persamaan 1.**"
      ],
      "metadata": {
        "id": "1nXj0r1ce3Px"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvY1ilJkeyDa",
        "outputId": "546678a1-baac-437b-d1b8-9bce770e93ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 0.16666666666666666, 0.3333333333333333, 0.6666666666666666, 1.0]\n"
          ]
        }
      ],
      "source": [
        "def norm_data(data):\n",
        "  '''\n",
        "  Melakukan normalisasi data.\n",
        "\n",
        "  Parameter:_\n",
        "    data (list) : Data yang akan dinormalisasi\n",
        "\n",
        "  Returns:\n",
        "    data (list) : Data hasil normalisasi\n",
        "  '''\n",
        "\n",
        "  data_max = max(data)\n",
        "  data_min = min(data)\n",
        "  data_len = len(data)\n",
        "\n",
        "  for i in range(0, data_len):\n",
        "    data[i] = (data[i] - data_min) / (data_max - data_min)\n",
        "\n",
        "  return data\n",
        "\n",
        "# contoh penggunaan\n",
        "data = [10, 11, 12, 14, 16]\n",
        "n_data = norm_data(data) # melakukan normalisasi\n",
        "print(n_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kode 1-2 merupakan implementasi normalisasi dengan menggunakan library Scikit-learn untuk kasus data fitur dalam bentuk 2 dimensi\n",
        "(2d list atau 2d array).**"
      ],
      "metadata": {
        "id": "OlbMPXUdgMm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "np.set_printoptions(precision=6) # bulatkan 4 angka koma\n",
        "np.set_printoptions(suppress=True) # hilangkan nilai e\n",
        "\n",
        "# Kita akan membentuk data\n",
        "# Hal ini dikarenakan, scikit-learn hanya menerima input dalam bentkan n-dimensional array\n",
        "data = [\n",
        "    [100, 0.0001],\n",
        "    [50, 0.05],\n",
        "    [30, 0.003],\n",
        "]\n",
        "\n",
        "# Ubah ke bentuk numpy n-dimensional array\n",
        "data = np.array(data)\n",
        "print('Data Asli')\n",
        "print(data)\n",
        "\n",
        "# Mendefinisikan obyek MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "# Transformasikan data\n",
        "scaled = scaler.fit_transform(data) # Fungsi normalisasi pada library Scikit-learn berasal dari kelas ‘MinMaxScaler’\n",
        "print('Data Normalisasi')\n",
        "print(scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bhf6knYkgT4I",
        "outputId": "04ee082a-aa2e-468d-9fbf-7dd12c70afd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Asli\n",
            "[[100.       0.0001]\n",
            " [ 50.       0.05  ]\n",
            " [ 30.       0.003 ]]\n",
            "Data Normalisasi\n",
            "[[1.       0.      ]\n",
            " [0.285714 1.      ]\n",
            " [0.       0.058116]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementasi Standarisasi**\n",
        "<br>\n",
        "Kode 1-3 merupakan implementasi standarisasi dengan menggunakan library Scikit-learn. Pada Scikit-learn, standarisasi dapat dilakukan dengan menggunakan kelas ‘StandardScaler’."
      ],
      "metadata": {
        "id": "xFIYCT2GiCTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "np.set_printoptions(precision=6) # bulatkan 4 angka koma\n",
        "np.set_printoptions(suppress=True) # hilangkan nilai e\n",
        "\n",
        "# Kita akan membentuk data\n",
        "# Hal ini dikarenakan, scikit-learn hanya menerima input dalam bentkan n-dimensional array\n",
        "data = [\n",
        "    [100, 0.0001],\n",
        "    [50, 0.05],\n",
        "    [30, 0.003],\n",
        "]\n",
        "\n",
        "# Ubah ke bentuk numpy n-dimensional array\n",
        "print(data)\n",
        "data = np.array(data)\n",
        "print('Data Asli')\n",
        "print(data)\n",
        "\n",
        "# Mendefinisikan obyek StandardScaler\n",
        "scaler = StandardScaler()\n",
        "# Transformasikan data\n",
        "scaled = scaler.fit_transform(data) # Fungsi normalisasi pada library Scikit-learn berasal dari kelas ‘MinMaxScaler’\n",
        "print('Data Standarisasi')\n",
        "print(scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpuWQdgHiPcI",
        "outputId": "61450354-f904-49b1-b8b3-fd6f31f39eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[100, 0.0001], [50, 0.05], [30, 0.003]]\n",
            "Data Asli\n",
            "[[100.       0.0001]\n",
            " [ 50.       0.05  ]\n",
            " [ 30.       0.003 ]]\n",
            "Data Standarisasi\n",
            "[[ 1.358732 -0.76956 ]\n",
            " [-0.339683  1.412317]\n",
            " [-1.019049 -0.642757]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementasi Ordinal Encoding**\n",
        "<br>\n",
        "Pada percobaan ini kita akan mencoba melakukan ordinal encoding dengan mengimport kelas ‘OrdinalEncoder’."
      ],
      "metadata": {
        "id": "XhDgYEeeiqqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# Inisiasi obyek Ordinal Encoder\n",
        "oe = OrdinalEncoder()\n",
        "\n",
        "# Definisikan data dalam bentuk 2d\n",
        "data = [\n",
        "    ['Politeknik Negeri Malang'],\n",
        "    ['Politeknik Elektronika Negeri Surabaya'],\n",
        "    ['Politeknik Negeri Jakarta'],\n",
        "    ['Politeknik Negeri Semarang'],\n",
        "]\n",
        "\n",
        "# Transformasi Ordinal Encoder\n",
        "transform_oe = oe.fit_transform(data)\n",
        "\n",
        "print('Data Asli')\n",
        "print(data)\n",
        "\n",
        "print('Data Transformasi Ordinal Encoder')\n",
        "print(transform_oe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UJXd_H4i4S5",
        "outputId": "03fb519c-f9f6-4f80-eaa0-51900e10a708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Asli\n",
            "[['Politeknik Negeri Malang'], ['Politeknik Elektronika Negeri Surabaya'], ['Politeknik Negeri Jakarta'], ['Politeknik Negeri Semarang']]\n",
            "Data Transformasi Ordinal Encoder\n",
            "[[2.]\n",
            " [0.]\n",
            " [1.]\n",
            " [3.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementasi One-Hot Encoding**\n",
        "<br>\n",
        "Pada bagian ini, kita akan mempelajari bagaimana cara mengimplementasikan\n",
        "one-hot encoding dengan menggunakan Scikit-learn kelas ‘OneHotEncoder’."
      ],
      "metadata": {
        "id": "69JieXa8j4Ct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Inisiasi obyek One Hot Encoder\n",
        "ohe = OneHotEncoder()\n",
        "\n",
        "# Definisikan data dalam bentuk 2d\n",
        "data = [\n",
        "    ['Politeknik Negeri Malang'],\n",
        "    ['Politeknik Elektronika Negeri Surabaya'],\n",
        "    ['Politeknik Negeri Jakarta'],\n",
        "    ['Politeknik Negeri Semarang'],\n",
        "]\n",
        "\n",
        "# Transformasi One Hot Encoder\n",
        "transform_ohe = ohe.fit_transform(data)\n",
        "\n",
        "print('Data Asli')\n",
        "print(data)\n",
        "\n",
        "print('Data Transformasi One-Hot Encoder')\n",
        "print(transform_ohe.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_rgk9FqkFy1",
        "outputId": "f1d15f62-3e8b-41c9-d6dc-1e1690c70b4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Asli\n",
            "[['Politeknik Negeri Malang'], ['Politeknik Elektronika Negeri Surabaya'], ['Politeknik Negeri Jakarta'], ['Politeknik Negeri Semarang']]\n",
            "Data Transformasi One-Hot Encoder\n",
            "[[0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementasi Dummy Variable Encoding**\n",
        "<br>\n",
        "Pada Scikit-learn, dummy variable encoding dapat dilakukan dengan menggunakan kelas yang sama dengan one-hot encoding yaitu dengan kelas ‘OneHotEncoding’. Namun, pada implementasi dummy variable encoding, perlu\n",
        "di definisikan parameter ‘drop’ dengan nilai ‘first’."
      ],
      "metadata": {
        "id": "fRKDMT5qkosY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Inisiasi obyek One Hot Encoder\n",
        "ohe = OneHotEncoder(drop='first')\n",
        "\n",
        "# Definisikan data dalam bentuk 2d\n",
        "data = [\n",
        "    ['Politeknik Negeri Malang'],\n",
        "    ['Politeknik Elektronika Negeri Surabaya'],\n",
        "    ['Politeknik Negeri Jakarta'],\n",
        "    ['Politeknik Negeri Semarang'],\n",
        "]\n",
        "\n",
        "# Transformasi One Hot Encoder\n",
        "transform_ohe = ohe.fit_transform(data)\n",
        "\n",
        "print('Data Asli')\n",
        "print(data)\n",
        "\n",
        "print('Data Transformasi One-Hot Encoder')\n",
        "print(transform_ohe.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EMKlNh8k8uh",
        "outputId": "e17ddc33-d5ff-4a9a-d8ef-1ce120536dbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Asli\n",
            "[['Politeknik Negeri Malang'], ['Politeknik Elektronika Negeri Surabaya'], ['Politeknik Negeri Jakarta'], ['Politeknik Negeri Semarang']]\n",
            "Data Transformasi One-Hot Encoder\n",
            "[[0. 1. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Studi Kasus Ekstrasi Fitur dari Data Teks**\n",
        "<br>\n",
        "Data teks sering kali membutuhkan proses pra pengolahan data sebelum data tersebut dilatih dengan model pembelajaran mesin. Proses pra pengolahan data teks bertujuan untuk membuat dokumen masukan lebih konsisten dan mempermudah representasi teks. Pada pengolahan data teks secara umum berisi tiga proses utama yaitu tokenizing, stopword removal, dan stemming."
      ],
      "metadata": {
        "id": "2l41a61HljkW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Siapkan data teks"
      ],
      "metadata": {
        "id": "jp9QkVVbmikq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    'the house had a tiny little mouse',\n",
        "    'the cat saw the mouse',\n",
        "    'the mouse ran away from the house',\n",
        "    'the cat finally ate the mouse',\n",
        "    'the end of the mouse story',\n",
        "]"
      ],
      "metadata": {
        "id": "ynnlGVSqmfvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Lakukan pembobotan dengan menggunakan metode TF-IDF, digunakan konfigurasi ‘stopword’ dengan nilai ‘english’. Konfigurasi dilakukan karena kita menggunakan kata dalam bahasa inggris."
      ],
      "metadata": {
        "id": "XJdfSqKknM_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Inisiasi obyek TfidfVectorizer\n",
        "vect = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# Pembobotan TF-IDF\n",
        "resp = vect.fit_transform(corpus)\n",
        "\n",
        "# Cetak hasil\n",
        "print(resp)\n",
        "print(resp.toarray())\n",
        "\n",
        "# Kolom 1 merupakan indeks dari dokumen pada corpus.\n",
        "# Kolom 2 merupakan indeks dari token yang terdapat dalam kalimat.\n",
        "# Kolom 3 merupakan bobot dari TF-IDF hasil kalkukasi."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66FVDbsenRDo",
        "outputId": "369dc881-d269-4b16-c9ca-c5ca63aa6d1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 7)\t0.2808823162882302\n",
            "  (0, 6)\t0.5894630806320427\n",
            "  (0, 11)\t0.5894630806320427\n",
            "  (0, 5)\t0.47557510189256375\n",
            "  (1, 9)\t0.7297183669435993\n",
            "  (1, 2)\t0.5887321837696324\n",
            "  (1, 7)\t0.3477147117091919\n",
            "  (2, 1)\t0.5894630806320427\n",
            "  (2, 8)\t0.5894630806320427\n",
            "  (2, 7)\t0.2808823162882302\n",
            "  (2, 5)\t0.47557510189256375\n",
            "  (3, 0)\t0.5894630806320427\n",
            "  (3, 4)\t0.5894630806320427\n",
            "  (3, 2)\t0.47557510189256375\n",
            "  (3, 7)\t0.2808823162882302\n",
            "  (4, 10)\t0.6700917930430479\n",
            "  (4, 3)\t0.6700917930430479\n",
            "  (4, 7)\t0.3193023297639811\n",
            "[[0.       0.       0.       0.       0.       0.475575 0.589463 0.280882\n",
            "  0.       0.       0.       0.589463]\n",
            " [0.       0.       0.588732 0.       0.       0.       0.       0.347715\n",
            "  0.       0.729718 0.       0.      ]\n",
            " [0.       0.589463 0.       0.       0.       0.475575 0.       0.280882\n",
            "  0.589463 0.       0.       0.      ]\n",
            " [0.589463 0.       0.475575 0.       0.589463 0.       0.       0.280882\n",
            "  0.       0.       0.       0.      ]\n",
            " [0.       0.       0.       0.670092 0.       0.       0.       0.319302\n",
            "  0.       0.       0.670092 0.      ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Untuk mendapatkan token kata-kata yang didapatkan dari proses stopwords"
      ],
      "metadata": {
        "id": "cIsZy8jaoOdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vect.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hze3-qA3oXEc",
        "outputId": "e1e80aac-e236-4e35-b3e0-de552081eaca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ate', 'away', 'cat', 'end', 'finally', 'house', 'little', 'mouse',\n",
              "       'ran', 'saw', 'story', 'tiny'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Pada proses ini, kita telah selesai melakukan ektraksi fitur teks yang hasilnya disimpan pada variabel ‘resp’."
      ],
      "metadata": {
        "id": "UKq-E26xoqMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "corpus = [\n",
        "    'the house had a tiny little mouse',\n",
        "    'the cat saw the mouse',\n",
        "    'the mouse ran away from the house',\n",
        "    'the cat finally ate the mouse',\n",
        "    'the end of the mouse story',\n",
        "]\n",
        "\n",
        "# Inisiasi obyek TfidfVectorizer\n",
        "vect = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# Pembobotan TF-IDF\n",
        "resp = vect.fit_transform(corpus)\n",
        "\n",
        "# Cetak hasil\n",
        "print('Hasil TF-IDF')\n",
        "print(resp)\n",
        "\n",
        "# Cetak token hasil stopword\n",
        "print('Hasil Token')\n",
        "print(vect.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snL9SSzrosue",
        "outputId": "7014630e-c5bd-4ea3-aaba-ef13bd66b33c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil TF-IDF\n",
            "  (0, 7)\t0.2808823162882302\n",
            "  (0, 6)\t0.5894630806320427\n",
            "  (0, 11)\t0.5894630806320427\n",
            "  (0, 5)\t0.47557510189256375\n",
            "  (1, 9)\t0.7297183669435993\n",
            "  (1, 2)\t0.5887321837696324\n",
            "  (1, 7)\t0.3477147117091919\n",
            "  (2, 1)\t0.5894630806320427\n",
            "  (2, 8)\t0.5894630806320427\n",
            "  (2, 7)\t0.2808823162882302\n",
            "  (2, 5)\t0.47557510189256375\n",
            "  (3, 0)\t0.5894630806320427\n",
            "  (3, 4)\t0.5894630806320427\n",
            "  (3, 2)\t0.47557510189256375\n",
            "  (3, 7)\t0.2808823162882302\n",
            "  (4, 10)\t0.6700917930430479\n",
            "  (4, 3)\t0.6700917930430479\n",
            "  (4, 7)\t0.3193023297639811\n",
            "Hasil Token\n",
            "['ate' 'away' 'cat' 'end' 'finally' 'house' 'little' 'mouse' 'ran' 'saw'\n",
            " 'story' 'tiny']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tugas Praktikum**\n",
        "1. Salin kalimat pada Kode 1-7 dengan tanda baca titik pada setiap kalimatnya dengan menggunakan editor teks.\n",
        "2. Simpan kalimat tersebut pada file ‘.txt’ dengan nama ‘corpus.txt’.\n",
        "3. Lakukan proses ektraksi fitur TF-IDF dengan menggunakan file ‘corpus.txt’."
      ],
      "metadata": {
        "id": "7vBzCgZppEYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Membaca file 'corpus.txt'\n",
        "with open('corpus.txt', 'r') as file:\n",
        "    corpus = file.readlines()\n",
        "\n",
        "# Inisiasi obyek TfidfVectorizer\n",
        "vect = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# Pembobotan TF-IDF\n",
        "resp = vect.fit_transform(corpus)\n",
        "\n",
        "# Menampilkan hasil dalam bentuk dense array\n",
        "print(resp.toarray())\n",
        "\n",
        "# Menampilkan fitur-fitur yang diekstraksi\n",
        "print(vect.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9ui5IVApKug",
        "outputId": "96f80fb3-e6bb-4ddd-e45f-6ec001150573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.       0.       0.       0.       0.       0.475575 0.589463 0.280882\n",
            "  0.       0.       0.       0.589463]\n",
            " [0.       0.       0.588732 0.       0.       0.       0.       0.347715\n",
            "  0.       0.729718 0.       0.      ]\n",
            " [0.       0.589463 0.       0.       0.       0.475575 0.       0.280882\n",
            "  0.589463 0.       0.       0.      ]\n",
            " [0.589463 0.       0.475575 0.       0.589463 0.       0.       0.280882\n",
            "  0.       0.       0.       0.      ]\n",
            " [0.       0.       0.       0.670092 0.       0.       0.       0.319302\n",
            "  0.       0.       0.670092 0.      ]]\n",
            "['ate' 'away' 'cat' 'end' 'finally' 'house' 'little' 'mouse' 'ran' 'saw'\n",
            " 'story' 'tiny']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to html /content/ML-Week2.ipynbs"
      ],
      "metadata": {
        "id": "-zDtYI-8tL9m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}